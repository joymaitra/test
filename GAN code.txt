import tensorflow as tf
import pandas as pd
import numpy as np

# Load the data from the CSV file into a Pandas DataFrame
df = pd.read_csv("data.csv")

# Preprocess the data by normalizing it to the range [-1, 1]
data = (df.values - df.values.mean()) / df.values.std()

# Set the dimensions of the generator and discriminator networks
gen_input_dim = 100
disc_input_dim = data.shape[1]

# Define the generator network
generator = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation="relu", input_dim=gen_input_dim),
    tf.keras.layers.Dense(disc_input_dim, activation="tanh")
])

# Define the discriminator network
discriminator = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation="relu", input_dim=disc_input_dim),
    tf.keras.layers.Dense(1, activation="sigmoid")
])

# Compile the discriminator network
discriminator.compile(optimizer="adam", loss="binary_crossentropy")

# Combine the generator and discriminator networks into a GAN
gan = tf.keras.Sequential([generator, discriminator])

# Compile the GAN
gan.compile(optimizer="adam", loss="binary_crossentropy")

# Train the GAN
for epoch in range(100):
    # Generate synthetic data
    noise = np.random.normal(0, 1, (data.shape[0], gen_input_dim))
    synthetic_data = generator.predict(noise)

    # Train the discriminator on real and synthetic data
    real_labels = np.ones((data.shape[0], 1))
    synthetic_labels = np.zeros((data.shape[0], 1))
    disc_loss_real = discriminator.train_on_batch(data, real_labels)
    disc_loss_synthetic = discriminator.train_on_batch(synthetic_data, synthetic_labels)
    disc_loss = 0.5 * np.add(disc_loss_real, disc_loss_synthetic)

    # Train the generator to fool the discriminator
    noise = np.random.normal(0, 1, (data.shape[0], gen_input_dim))
    gan_labels = np.ones((data.shape[0], 1))
    gan_loss = gan.train_on_batch(noise, gan_labels)

    # Print the loss values for each epoch
    print("Epoch: %d, Discriminator Loss: %f, GAN Loss: %f" % (epoch, disc_loss, gan_loss))

# Use the generator to generate synthetic data
noise = np.random.normal(0, 1, (100, gen_input_dim))
synthetic_data = generator.p
# Save the generated synthetic data to a CSV file
synthetic_df = pd.DataFrame(synthetic_data, columns=df.columns)
synthetic_df.to_csv("synthetic_data.csv", index=False)
